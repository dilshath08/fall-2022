{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a-JyHIXOtnHeRuWI8dxuYaWb54gcEjWs",
      "authorship_tag": "ABX9TyOc86GcyCxXdMiAJwVByQWI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilshath08/fall-2022/blob/main/do_or_die.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CDJ4sddTnUSH"
      },
      "outputs": [],
      "source": [
        "!pip install openslide-python\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip3 install addict\n",
        "!pip install imagecodecs\n",
        "!pip install pyvips\n",
        "!apt update && apt install -y openslide-tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python efficientnet.py"
      ],
      "metadata": {
        "id": "qLt9K2AzrOwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python general.py"
      ],
      "metadata": {
        "id": "y59JvfLnrg-n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python image_augmentation.py"
      ],
      "metadata": {
        "id": "888rVVrRrlsh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python k_fold.py"
      ],
      "metadata": {
        "id": "kY7kYESQr0GJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python layer.py"
      ],
      "metadata": {
        "id": "u74TV_HQsAcq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python loss.py"
      ],
      "metadata": {
        "id": "RpYgxMIIsUl9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python loss_tile.py"
      ],
      "metadata": {
        "id": "Sun2ma-OsXl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python metrics.py"
      ],
      "metadata": {
        "id": "spLmlAIEsb8P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python pandadataset.py"
      ],
      "metadata": {
        "id": "pM49ixTzslTv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tile.py"
      ],
      "metadata": {
        "id": "SYctic5hsoS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tile_new.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug3btr2rsuJM",
        "outputId": "8030270f-f589-4022-d3a5-abd5c6db0ef7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/tile_new.py\", line 69, in <module>\n",
            "    img = skimage.io.MultiImage(os.path.join(TRAIN,name+'.tiff'))[-1]\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/skimage/io/collection.py\", line 274, in __getitem__\n",
            "    n = self._check_imgnum(n)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/skimage/io/collection.py\", line 330, in _check_imgnum\n",
            "    raise IndexError(\"There are only %s images in the collection\"\n",
            "IndexError: There are only 0 images in the collection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python small_csv.py"
      ],
      "metadata": {
        "id": "x-9MTh9rtUUd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python trainer.py"
      ],
      "metadata": {
        "id": "phgweOLFtXWt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9t4ImbitacD",
        "outputId": "b44eae71-a671-4ddc-a03d-664bfc2d7dd7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-27 06:54:27.342998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-27 06:54:29.051576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-27 06:54:29.051815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-27 06:54:29.051844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            " ==== 1 fold ====\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train.py\", line 103, in <module>\n",
            "    logits = model(images)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/parallel/data_parallel.py\", line 153, in forward\n",
            "    return self.module(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/efficientnet.py\", line 86, in forward\n",
            "    x = self.basemodel(x)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/efficientnet_pytorch/model.py\", line 314, in forward\n",
            "    x = self.extract_features(inputs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/efficientnet_pytorch/model.py\", line 289, in extract_features\n",
            "    x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/efficientnet_pytorch/utils.py\", line 275, in forward\n",
            "    x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
            "RuntimeError: Given groups=1, weight of size [32, 3, 3, 3], expected input[4, 1, 1025, 1025] to have 3 channels, but got 1 channels instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2mK6TA4tcLY",
        "outputId": "17f78150-1858-483f-f23d-81bda7afecd8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/test.py\", line 32, in <module>\n",
            "    cfg = read_yaml(yaml_name)   \n",
            "  File \"/content/general.py\", line 16, in read_yaml\n",
            "    with open(fpath, mode=\"r\") as file:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'configs/011.yaml'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZGWoKR2tjFc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}